# Multi-dimensional Classification of AI Risk Incidents

[[查看中文版]](README_zh-CN.md "go")

## Overview

This part focuses on the multi-dimensional classification of AI risk incidents, aiming to establish a unified taxonomy (RiskNet Taxonomy) and benchmark dataset, as well as provide code implementations for model evaluation. The core goal is to compare the performance of prompt-based inference and fine-tuned Large Language Models (LLMs) in multi-dimensional classification tasks, offering technical support for the structured analysis of AI risk incidents.

## Project Structure and File Descriptions

### 1. `classification_result` Folder

This folder stores classification results of different models in JSON format. Each file corresponds to the prediction outputs of a specific model on the test set, with details as follows:

- **Filename Format**: `<model_name>.json` (e.g., `qwen3-14B-sft.json`, `kimi-k2-prompt.json`)
- **Content**: A list of dictionaries, where each dictionary contains two key-value pairs:
  - `label`: Ground-truth annotations, including single-label tasks (entity, intent, timing, EU AI Act risk level) and multi-label tasks (domain classification with main/subdomains)
  - `predict`: Model predictions, with the same format as `label`
- **Purpose**: Serves as input for the evaluation script to calculate various performance metrics.

### 2. `evaluation_result` Folder

This folder stores evaluation reports generated by the evaluation script in TXT format. Each file corresponds to the performance metrics of a specific model, including:

- **Filename Format**: `<model_name>.txt` (consistent with model names in `classification_result`)
- **Content**:
  - Metrics for single-label tasks (accuracy, precision, recall, and F1-score for entity, intent, timing, and risk level)
  - Metrics for multi-label tasks (Hamming loss, micro/macro average accuracy, precision, recall, and F1-score for main domains and subdomains)
- **Purpose**: Intuitively presents performance differences between models, providing a basis for result analysis and conclusion drawing.

### 3. `fine-tuning-data` Folder

This folder contains datasets used for model fine-tuning, constructed according to the following rules:

- **Data Source**: Derived from the top 5 representative news reports of each AI risk incident in the standard incident dataset.
- **Processing Method**: For each incident, the titles and abstracts of the 5 news reports are aggregated and summarized into a concise text (retaining key information about the incident).
- **Input-Output Structure**:
  - **Input**: Aggregated summary of the incident
  - **Output**: Multi-dimensional labels corresponding to the incident (risk level, domain tags, causal tags)
- **Split Ratio**: The dataset is divided into a training set and a validation set in an 8:2 ratio for model fine-tuning.
- **Purpose**: Provides high-quality supervised data for LLM fine-tuning, helping models learn risk-related patterns and improve classification accuracy.

### 4. Core Evaluation Script (Python Code)

This script implements the logic for evaluating model performance, with core functions including:

- **Data Validation**: Checks the validity of labels and predictions (e.g., ensuring single-label values are integers and multi-label formats are lists).
- **Metric Calculation**:

  - For single-label tasks (risk level, causal tags): Computes accuracy, precision, recall, and F1-score.
  - For multi-label tasks (domains/subdomains): Computes Hamming loss, micro/macro average metrics, and accuracy for each category.
- **Result Output**: Writes evaluation metrics to TXT files in the `evaluation_result` folder for easy review.
- **Usage Example**:

  ```python
  # Evaluate the fine-tuned qwen3-32B model
  evaluate_model("classification_result/qwen3-32B-sft.json", "qwen3-32B-sft")
  ```
